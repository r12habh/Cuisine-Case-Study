# -*- coding: utf-8 -*-
"""Data Science Methodology

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hiYNU8pQavL1f_DrOHVyH5Xrr68iSU__

#Introduction

The aim of this notebook is to reinforce the concepts of  Data Science Methodology. This notebook will revolve around the use case of food recipes, and will walk through the process that data scientists usually follow when trying to solve a problem. Let's get started!

## Table of Contents

<div class="alert alert-block alert-info" style="margin-top: 20px">

1. [Business Understanding](#0)<br>
2. [Analytic Approach](#2) <br>
3. [Data Requirements](#4) <br>
4. [Data Collection](#6) <br>
5. [Data Understanding](#8) <br>
6. [Data Preparation](#10) <br>
7. [Data Modeling](#12) <br>
8. [Model Evaluation](#14) <br>
</div>
<hr>

# Business Understanding <a id="1"></a>

This is the **Data Science Methodology**, a flowchart that begins with business understanding.

<img src="https://ibm.box.com/shared/static/eyl60n09iige3eo5tac3dweqko2s58oo.png" width=500>

####Q. Why is the business understanding stage important?
Answer :<br>
It helps clarify the goal of the entity asking the question.

#### Looking at this diagram, we immediately spot two outstanding features of the data science methodology.

<img src = "https://ibm.box.com/shared/static/6u3evi4h52e80cq78alqgza8nhfy8vhl.png" width = 500>

**1. The flowchart is highly iterative.** <br>
**2. The flowchart never ends.**

#### Now let's illustrate the data science methodology with a case study.

Say, we are interested in automating the process of figuring out the cuisine of a given dish or recipe. Let's apply the business understanding stage to this problem.

#### Q. Can we predict the cuisine of a given dish using the name of the dish only?
Answer : <br>
No.
"""



"""#### Q. For example, the following dish names were taken from the menu of a local restaurant in Toronto, Ontario in Canada. 

#### 1. Beast
#### 2. 2 PM
#### 3. 4 Minute


The cuisine is <strong>Japanese</strong>. Here are links to the images of the dishes: 

Beast: https://ibm.box.com/shared/static/5e7duvewfl5bk4317sna5skvdhrehro2.png

2PM: https://ibm.box.com/shared/static/d9xuzqm8cq76zxxcc0f9gdts4iksipyk.png

4 Minute: https://ibm.box.com/shared/static/f1fwvvwn4u8rx8tghep6zyj5pi6a8v8k.png

Photographs by Avlxyz: https://commons.wikimedia.org/wiki/Category:Photographs_by_Avlxyz

#### Q. What about by appearance only?
Answer :<br>
No, especially when it comes to countries in close geographical proximity such as Scandinavian countries, or Asian countries.

At this point, we realize that automating the process of determining the cuisine of a given dish is not a straightforward problem as we need to come up with a way that is very robust to the many cuisines and their variations.

#### Q. What about determining the cuisine of a dish based on its ingredients?
Answer :<br>
Potentially yes, as there are specific ingredients unique to each cuisine.
<br>
Determining the cuisine of a given dish based on its ingredients seems like a viable solution as some ingredients are unique to cuisines. For example:
* When we talk about **American** cuisines, the first ingredient that comes to one's mind (or at least to my mind =D) is beef or turkey.

* When we talk about **British** cuisines, the first ingredient that comes to one's mind is haddock or mint sauce.

* When we talk about **Canadian** cuisines, the first ingredient that comes to one's mind is bacon or poutine.

* When we talk about **French** cuisines, the first ingredient that comes to one's mind is bread or butter.

* When we talk about **Italian** cuisines, the first ingredient that comes to one's mind is tomato or ricotta.

* When we talk about **Japanese** cuisines, the first ingredient that comes to one's mind is seaweed or soy sauce.

* When we talk about **Chinese** cuisines, the first ingredient that comes to one's mind is ginger or garlic.

* When we talk about **indian** cuisines, the first ingredient that comes to one's mind is masala or chillis.

#### Accordingly, we can determine the cuisine of the dish associated with the following list of ingredients?
<img src="https://ibm.box.com/shared/static/bs81fv2n5lidkv9hg827qn5s86gdk090.png" width=600>
Answer :<br>
Japanese since the recipe is most likely that of a sushi roll.

# Analytic Approach <a id="2"></a>

<img src="https://ibm.box.com/shared/static/i19z7bijbksl5kkmm81ngg39y0ruzirh.png" width=500>
#### So why are we interested in data science?
Once the business problem has been clearly stated, the data scientist can define the analytic approach to solve the problem. This step entails expressing the problem in the context of statistical and machine-learning techniques, so that the entity or stakeholders with the problem can identify the most suitable techniques for the desired outcome. 
#### Why is the analytic approach stage important?
Because it helps identify what type of patterns will be needed to address the question most effectively.
#### Let's explore a machine learning algorithm, decision trees, and see if it is the right technique to automate the process of identifying the cuisine of a given dish or recipe while simultaneously providing us with some insight on why a given recipe is believed to belong to a certain type of cuisine.
This is a decision tree that a naive person might create manually. Starting at the top with all the recipes for all the cuisines in the world, if a recipe contains **rice**, then this decision tree would classify it as a **Japanese** cuisine. Otherwise, it would be classified as not a **Japanese** cuisine.<br>
<img src="https://ibm.box.com/shared/static/1dzmelrcfsgba47rbbagbxiqisqgy63n.png" width=500>
#### Is this a good decision tree?
No, because a plethora of dishes from other cuisines contain rice. Therefore, using rice as the ingredient in the Decision node to split on is not a good choice.
#### In order to build a very powerful decision tree for the recipe case study, let's take some time to learn more about decision trees.
* Decision trees are built using recursive partitioning to classify the data.
* When partitioning the data, decision trees use the most predictive feature (ingredient in this case) to split the data.
* **Predictiveness** is based on decrease in entropy - gain in information, or *impurity*.

#### Suppose that our data is comprised of green triangles and red circles.
The following decision tree would be considered the optimal model for classifying the data into a node for green triangles and a node for red circles.
<img src="https://ibm.box.com/shared/static/obwksbsin10mlg2m8x8ehe9xeyjfizqx.png" width=400>

Each of the classes in the leaf nodes are completely pure â€“ that is, each leaf node only contains datapoints that belong to the same class.<br>
On the other hand, the following decision tree is an example of the worst-case scenario that the model could output. 
<img src="https://ibm.box.com/shared/static/qenfaznfhwvvvlkjtzjirqgb4j5xx48l.png" width=500>
<br>
Each leaf node contains datapoints belonging to the two classes resulting in many datapoints ultimately being misclassified.
#### A tree stops growing at a node when:
* Pure or nearly pure.
* No remaining variables on which to further subset the data.
* The tree has grown to a preselected size limit.

#### Here are some characteristics of decision trees:
<img src="https://ibm.box.com/shared/static/05mkemi191f6hbhw6f3ewrusckkgu861.png" width=800>

Now let's put what we learned about decision trees to use. Let's try and build a much better version of the decision tree for our recipe problem.
<img src="https://ibm.box.com/shared/static/e1ok280uavy6k8u7loli59ftoz66kk1s.png" width = 500>
<br>
The above decision tree is a much better version than the previous one. Although we are still using **Rice** as the ingredient in the first *decision node*, recipes get divided into **Asian Food** and **Non-Asian Food**. **Asian Food** is then further divided into **Japanese** and **Not Japanese** based on the **Wasabi** ingredient. This process of splitting *leaf nodes* continues until each *leaf node* is pure, i.e., containing recipes belonging to only one cuisine. <br>

Accordingly, decision trees is a suitable technique or algorithm for our recipe case study.

# Data Requirements <a id="4"></a>

<img src="https://ibm.box.com/shared/static/dv60vn9nq3kb3n7efc5lxtxfgp11stfz.png" width=500>

The chosen analytic approach determines the data requirements. Specifically, the analytic methods to be used require certain data content, formats and representations, guided by domain knowledge. <br>
We have already determined that automating the process of determining the cuisine of a given recipe or dish is potentially possible using the ingredients of the recipe or the dish. In order to build a model, we need extensive data of different cuisines and recipes. <br>

Identifying the required data fulfills the data requirements stage of the data science methodology.

-----------

# Data Collection <a id="6"></a>

<img src = "https://ibm.box.com/shared/static/hgocgq6no4d09pbr140hmt3jtjizy2da.png" width=500>

In the initial data collection stage, data scientists identify and gather the available data resources. These can be in the form of structured, unstructured, and even semi-structured data relevant to the problem domain.
#### Web Scraping of Online Food Recipes 

A researcher named Yong-Yeol Ahn scraped tens of thousands of food recipes (cuisines and ingredients) from three different websites, namely:

<img src = "https://ibm.box.com/shared/static/4fruwan7wmjov3gywiz3swlojw0srv54.png" width=500>

www.allrecipes.com

<img src = "https://ibm.box.com/shared/static/cebfdbr22fjxa47lltp0bs533r103g0z.png" width=500>

www.epicurious.com

<img src = "https://ibm.box.com/shared/static/epk727njg7xrz49pbkpkzd05cm5ywqmu.png" width=500>

www.menupan.com
<br>
For more information on Yong-Yeol Ahn and his research, you can read his paper on [Flavor Network and the Principles of Food Pairing](http://yongyeol.com/papers/ahn-flavornet-2011.pdf).

Luckily, we will not need to carry out any data collection as the data that we need to meet the goal defined in the business understanding stage is readily available.

Get the version of Python installed.
"""

# check Python version
!python -V

"""Read the data from the IBM server into a *pandas* dataframe."""

import pandas as pd # download library to read data into dataframe
pd.set_option('display.max_columns', None)

recipes = pd.read_csv("https://ibm.box.com/shared/static/5wah9atr5o1akuuavl2z9tkjzdinr1lv.csv")

print("Data read into dataframe!") # takes about 30 seconds

"""Show the first few rows."""

recipes.head()

"""Get the dimensions of the dataframe."""

recipes.shape

"""So our dataset consists of 57,691 recipes. Each row represents a recipe, and for each recipe, the corresponding cuisine is documented as well as whether 384 ingredients exist in the recipe or not beginning with almond and ending with zucchini.

-----------

Now that the data collection stage is complete, data scientists typically use descriptive statistics and visualization techniques to better understand the data and get acquainted with it. Data scientists, essentially, explore the data to:

* understand its content,
* assess its quality,
* discover any interesting preliminary insights, and,
* determine whether additional data is necessary to fill any gaps in the data.

# Data Understanding <a id="8"></a>

<img src="https://ibm.box.com/shared/static/89geb3m0ge1z73s92hl8o8wdcpcrggtz.png" width=500>
<br>
We know that a basic sushi recipe includes the ingredients:
* rice
* soy sauce
* wasabi
* some fish/vegetables

Let's check that these ingredients exist in our dataframe:
"""

import re # import library for regular expression

ingredients = list(recipes.columns.values)

print([match.group(0) for ingredient in ingredients for match in [(re.compile(".*(rice).*")).search(ingredient)] if match])
print([match.group(0) for ingredient in ingredients for match in [(re.compile(".*(wasabi).*")).search(ingredient)] if match])
print([match.group(0) for ingredient in ingredients for match in [(re.compile(".*(soy).*")).search(ingredient)] if match])

"""Yes, they do!

* rice exists as rice.
* wasabi exists as wasabi.
* soy exists as soy_sauce.

So maybe if a recipe contains all three ingredients: rice, wasabi, and soy_sauce, then we can confidently say that the recipe is a **Japanese** cuisine! Let's keep this in mind!

----------------

# Data Preparation <a id="10"></a>

<img src="https://ibm.box.com/shared/static/lqc2j3r0ndhokh77mubohwjqybzf8dhk.png" width=500>
<br>
In this section, we will prepare data for the next stage in the data science methodology, which is modeling. This stage involves exploring the data further and making sure that it is in the right format for the machine learning algorithm that we selected in the analytic approach stage, which is decision trees.
<br>

First, look at the data to see if it needs cleaning.
"""

recipes["country"].value_counts()    # frequency table

"""By looking at the above table, we can make the following observations:

1. Cuisine column is labeled as Country, which is inaccurate.
2. Cuisine names are not consistent as not all of them start with an uppercase first letter.
3. Some cuisines are duplicated as variation of the country name, such as Vietnam and Vietnamese.
4. Some cuisines have very few recipes.

#### Let's fixes these problems.
Fix the name of the column showing the cuisine.
"""

column_names = recipes.columns.values
column_names[0] = "cuisine"
recipes.columns = column_names

recipes

"""Make all the cuisine names lowercase."""

recipes["cuisine"] = recipes["cuisine"].str.lower()

"""Make the cuisine names consistent."""

recipes.loc[recipes["cuisine"] == "austria", "cuisine"] = "austrian"
recipes.loc[recipes["cuisine"] == "belgium", "cuisine"] = "belgian"
recipes.loc[recipes["cuisine"] == "china", "cuisine"] = "chinese"
recipes.loc[recipes["cuisine"] == "canada", "cuisine"] = "canadian"
recipes.loc[recipes["cuisine"] == "netherlands", "cuisine"] = "dutch"
recipes.loc[recipes["cuisine"] == "france", "cuisine"] = "french"
recipes.loc[recipes["cuisine"] == "germany", "cuisine"] = "german"
recipes.loc[recipes["cuisine"] == "india", "cuisine"] = "indian"
recipes.loc[recipes["cuisine"] == "indonesia", "cuisine"] = "indonesian"
recipes.loc[recipes["cuisine"] == "iran", "cuisine"] = "iranian"
recipes.loc[recipes["cuisine"] == "italy", "cuisine"] = "italian"
recipes.loc[recipes["cuisine"] == "japan", "cuisine"] = "japanese"
recipes.loc[recipes["cuisine"] == "israel", "cuisine"] = "jewish"
recipes.loc[recipes["cuisine"] == "korea", "cuisine"] = "korean"
recipes.loc[recipes["cuisine"] == "lebanon", "cuisine"] = "lebanese"
recipes.loc[recipes["cuisine"] == "malaysia", "cuisine"] = "malaysian"
recipes.loc[recipes["cuisine"] == "mexico", "cuisine"] = "mexican"
recipes.loc[recipes["cuisine"] == "pakistan", "cuisine"] = "pakistani"
recipes.loc[recipes["cuisine"] == "philippines", "cuisine"] = "philippine"
recipes.loc[recipes["cuisine"] == "scandinavia", "cuisine"] = "scandinavian"
recipes.loc[recipes["cuisine"] == "spain", "cuisine"] = "spanish_portuguese"
recipes.loc[recipes["cuisine"] == "portugal", "cuisine"] = "spanish_portuguese"
recipes.loc[recipes["cuisine"] == "switzerland", "cuisine"] = "swiss"
recipes.loc[recipes["cuisine"] == "thailand", "cuisine"] = "thai"
recipes.loc[recipes["cuisine"] == "turkey", "cuisine"] = "turkish"
recipes.loc[recipes["cuisine"] == "vietnam", "cuisine"] = "vietnamese"
recipes.loc[recipes["cuisine"] == "uk-and-ireland", "cuisine"] = "uk-and-irish"
recipes.loc[recipes["cuisine"] == "irish", "cuisine"] = "uk-and-irish"

recipes

"""Remove cuisines with < 50 recipes."""

import numpy as np # import numpy library

# get list of cuisines to keep
recipes_counts = recipes["cuisine"].value_counts()
cuisines_indices = recipes_counts > 50

cuisines_to_keep = list(np.array(recipes_counts.index.values)[np.array(cuisines_indices)])

rows_before = recipes.shape[0]
print("Number of rows of original dataframe is {}.".format(rows_before))

recipes = recipes.loc[recipes["cuisine"].isin(cuisines_to_keep)]

rows_after = recipes.shape[0]
print("Number of rows of processed dataframe is {}.".format(rows_after))

print("{} rows removed!".format(rows_before - rows_after))

"""Convert all Yes's to 1's and the No's to 0's"""

recipes = recipes.replace(to_replace="Yes", value=1)
recipes = recipes.replace(to_replace="No", value=0)

"""#### Let's analyze the data a little more in order to learn the data better and note any interesting preliminary observations.
The following cell gets the recipes that contain **rice** *and* **soy** *and* **wasabi** *and* **seaweed**.
"""

recipes.head()

check_recipes = recipes.loc[
    (recipes["rice"] == 1) &
    (recipes["soy_sauce"] == 1) &
    (recipes["wasabi"] == 1) &
    (recipes["seaweed"] == 1) 
]

check_recipes

"""####Based on the results of the above code, can we classify all recipes that contain **"rice"** *and* **"soy"** *and* **"wasabi"** *and* **"seaweed"** as **"Japanese"** recipes? Why? <br>
Answer : <br>
No, because other recipes such as Asian and East_Asian recipes also contain these ingredients.

Let's count the ingredients across all recipes.
"""

# sum each column
ing = recipes.iloc[:, 1:].sum(axis=0)

# define each column as a pandas series
ingredient = pd.Series(ing.index.values, index = np.arange(len(ing)))
count = pd.Series(list(ing), index = np.arange(len(ing)))

# create the dataframe
ing_df = pd.DataFrame(dict(ingredient = ingredient, count = count))
ing_df = ing_df[["ingredient", "count"]]
print(ing_df.to_string())

"""Now we have a dataframe of ingredients and their total counts across all recipes. Let's sort this dataframe in descending order."""

ing_df.sort_values(["count"], ascending=False, inplace=True)
ing_df.reset_index(inplace=True, drop=True)

print(ing_df)

"""####The 3 most popular ingredients?
1. Egg with <strong>21,025</strong> occurrences.<br>
2. Wheat with <strong>20,781</strong> occurrences. <br>
3. Butter with <strong>20,719</strong> occurrences.

However, note that there is a problem with the above table. There are ~40,000 American recipes in our dataset, which means that the data is biased towards American ingredients.<br>
**Therefore**, let's compute a more objective summary of the ingredients by looking at the ingredients per cuisine.
#### Let's create a *profile* for each cuisine.

In other words, let's try to find out what ingredients Chinese people typically use, and what is **Canadian** food for example.
"""

cuisines = recipes.groupby("cuisine").mean()
cuisines.head()

"""As shown above, we have just created a dataframe where each row is a cuisine and each column (except for the first column) is an ingredient, and the row values represent the percentage of each ingredient in the corresponding cuisine.

**For example**:

* *almond* is present across 15.65% of all of the **African** recipes.
* *butter* is present across 38.11% of all of the **Canadian** recipes.

Let's print out the profile for each cuisine by displaying the top four ingredients in each cuisine.
"""

num_ingredients = 4    # define number of top ingredients to print

# define a function that prints the top ingredients for each cuisine
def print_top_ingredients(row):
  print(row.name.upper())
  row_sorted = row.sort_values(ascending=False)*100
  top_ingredients = list(row_sorted.index.values)[0:num_ingredients]
  
  for ind, ingredient in enumerate(top_ingredients):
    print("%s (%d%%)" %(ingredient, row_sorted[ind]), end=' ')
  print("\n")
 


# apply function to cuisines dataframe
create_cuisines_profiles = cuisines.apply(print_top_ingredients, axis=1)

"""At this point, we feel that we have understood the data well and the data is ready and is in the right format for modeling!

-----------

# Data Modeling <a id="12"></a>

<img src="https://ibm.box.com/shared/static/d6fiatxvraho57fq3tfyblsf38fzi61f.png" width=500>

Download and install more libraries and dependies to build decision trees.
"""

# import decision trees scikit-learn libraries
# %matplotlib inline
from sklearn import tree
from sklearn.metrics import accuracy_score, confusion_matrix

import matplotlib.pyplot as plt

!pip install graphviz
import graphviz

from sklearn.tree import export_graphviz

import itertools

print("Done")

"""## [bamboo_tree] Only Asian and Indian Cuisines

Here, we are creating a decision tree for the recipes for just some of the Asian (Korean, Japanese, Chinese, Thai) and Indian cuisines. The reason for this is because the decision tree does not run well when the data is biased towards one cuisine, in this case American cuisines. One option is to exclude the American cuisines from our analysis or just build decision trees for different subsets of the data. Let's go with the latter solution.

Let's build our decision tree using the data pertaining to the Asian and Indian cuisines and name our decision tree *bamboo_tree*.
"""

# select subset of cuisines
asian_indian_recipes = recipes[recipes.cuisine.isin(["korean", "japanese", "chinese", "thai", "indian"])]
cuisines = asian_indian_recipes["cuisine"]
ingredients = asian_indian_recipes.iloc[:,1:]

bamboo_tree = tree.DecisionTreeClassifier(max_depth=7)
bamboo_tree.fit(ingredients, cuisines)

print("Decision tree model saved to bamboo_tree!")

"""Let's plot the decision tree and examine how it looks like."""

export_graphviz(bamboo_tree,
                feature_names=list(ingredients.columns.values),
                out_file="bamboo_tree.dot",
                class_names=np.unique(cuisines),
                filled=True,
                node_ids=True,
                special_characters=True,
                impurity=False,
                label="all",
                leaves_parallel=False)

with open("bamboo_tree.dot") as bamboo_tree_image:
    bamboo_tree_graph = bamboo_tree_image.read()
graphviz.Source(bamboo_tree_graph)

"""The decision tree learned:
* If a recipe contains *cumin* and *fish* and **no** *yoghurt*, then it is most likely a **Thai** recipe.
* If a recipe contains *cumin* but **no** *fish* and **no** *soy_sauce*, then it is most likely an **Indian** recipe.

We can analyze the remaining branches of the tree to come up with similar rules for determining the cuisine of different recipes.

# Model Evaluation <a id="14"></a>

<img src="https://ibm.box.com/shared/static/prc3kksci2a6deks36jpyf4cf4oxh74a.png" width=500>

To evaluate our model of Asian and Indian cuisines, we will split our dataset into a training set and a test set. We will build the decision tree using the training set. Then, we will test the model on the test set and compare the cuisines that the model predicts to the actual cuisines.

Let's first create a new dataframe using only the data pertaining to the Asian and the Indian cuisines, and let's call the new dataframe **bamboo**.
"""

bamboo = recipes[recipes.cuisine.isin(["korean", "japanese", "chinese", "thai", "indian"])]

"""Let's see how many recipes exist for each cuisine."""

bamboo["cuisine"].value_counts()

"""Let's remove 30 recipes from each cuisine to use as the test set, and let's name this test set **bamboo_test**."""

# set sample size
sample_n = 30

"""Create a dataframe containing 30 recipes from each cuisine, selected randomly."""

import random # library for random number generation

# take 30 recipes from each cuisine
random.seed(1234) # set random seed
bamboo_test = bamboo.groupby("cuisine", group_keys=False).apply(lambda x: x.sample(sample_n))

bamboo_test_ingredients = bamboo_test.iloc[:,1:] # ingredients
bamboo_test_cuisines = bamboo_test["cuisine"] # corresponding cuisines or labels

"""Check that there are 30 recipes for each cuisine."""

# check that we have 30 recipes from each cuisine
bamboo_test["cuisine"].value_counts()

"""Next, let's create the training set by removing the test set from the **bamboo** dataset, and let's call the training set **bamboo_train**."""

bamboo_test_index = bamboo.index.isin(bamboo_test.index)
bamboo_train = bamboo[~bamboo_test_index]

bamboo_train_ingredients = bamboo_train.iloc[:,1:] # ingredients
bamboo_train_cuisines = bamboo_train["cuisine"] # corresponding cuisines or labels

"""Check that there are 30 _fewer_ recipes now for each cuisine."""

bamboo_train["cuisine"].value_counts()

"""Let's build the decision tree using the training set, **bamboo_train**, and name the generated tree **bamboo_train_tree** for prediction."""

bamboo_train_tree = tree.DecisionTreeClassifier()
bamboo_train_tree.fit(bamboo_train_ingredients, bamboo_train_cuisines)

print("Decision tree model saved to bamboo_train_tree!")

"""Let's plot the decision tree and explore it."""

export_graphviz(bamboo_train_tree,
                feature_names=list(bamboo_train_ingredients.columns.values),
                out_file="bamboo_train_tree.dot",
                class_names=np.unique(bamboo_train_cuisines),
                filled=True,
                node_ids=True,
                special_characters=True,
                impurity=False,
                label="all",
                leaves_parallel=False)

with open("bamboo_train_tree.dot") as bamboo_train_tree_image:
    bamboo_train_tree_graph = bamboo_train_tree_image.read()
graphviz.Source(bamboo_train_tree_graph)

"""Now that we defined our tree to be deeper, more decision nodes are generated."""

bamboo_pred_cuisines = bamboo_train_tree.predict(bamboo_test_ingredients)

"""To quantify how well the decision tree is able to determine the cuisine of each recipe correctly, we will create a confusion matrix which presents a nice summary on how many recipes from each cuisine are correctly classified. It also sheds some light on what cuisines are being confused with what other cuisines.

So let's go ahead and create the confusion matrix for how well the decision tree is able to correctly classify the recipes in **bamboo_test**.
"""

test_cuisines = np.unique(bamboo_test_cuisines)
bamboo_confusion_matrix = confusion_matrix(bamboo_test_cuisines, bamboo_pred_cuisines, test_cuisines)
title = 'Bamboo Confusion Matrix'
cmap = plt.cm.Blues

plt.figure(figsize=(8, 6))
bamboo_confusion_matrix = (
    bamboo_confusion_matrix.astype('float') / bamboo_confusion_matrix.sum(axis=1)[:, np.newaxis]
    ) * 100

plt.imshow(bamboo_confusion_matrix, interpolation='nearest', cmap=cmap)
plt.title(title)
plt.colorbar()
tick_marks = np.arange(len(test_cuisines))
plt.xticks(tick_marks, test_cuisines)
plt.yticks(tick_marks, test_cuisines)

fmt = '.2f'
thresh = bamboo_confusion_matrix.max() / 2.
for i, j in itertools.product(range(bamboo_confusion_matrix.shape[0]), range(bamboo_confusion_matrix.shape[1])):
    plt.text(j, i, format(bamboo_confusion_matrix[i, j], fmt),
             horizontalalignment="center",
             color="white" if bamboo_confusion_matrix[i, j] > thresh else "black")

plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')

plt.show()

"""The rows represent the actual cuisines from the dataset and the columns represent the predicted ones. Each row should sum to 100%. According to this confusion matrix, we make the following observations:

* Using the first row in the confusion matrix, 60% of the **Chinese** recipes in **bamboo_test** were correctly classified by our decision tree whereas 10% of the **Chinese** recipes were misclassified as **Korean** and 13% were misclassified as **Indian**.

* Using the Indian row, 90% of the **Indian** recipes in **bamboo_test** were correctly classified by our decision tree and 3% of the **Indian** recipes were misclassified as **Chinese** and 0% were misclassified as **Korean** and 3% were misclassified as **Thai**.

* Using the confusion matrix, 63.33% **Japanese** recipes were correctly classified by our decision tree.

* Using the confusion matrix, 3.33% **Korean** recipes were misclassified as **Japanese**.

* **Thai** cuisine, with only 50% has the least number of recipes correctly classified by the decision tree using the confusion matrix.
"""

# This notebook was compiled by me.
# The contents of this notebook are part of the free course on **Cognitive Class** called *Data Science Methodology*.
# Feel free to contact me if you have any questions!